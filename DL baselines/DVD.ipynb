{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DVD.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFefv4k6ohaL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://raw.githubusercontent.com/avinashsai/Cross-domain-sentiment-analysis/master/Dataset/Actualdata/Books/Bookstrain.txt\n",
        "!wget https://raw.githubusercontent.com/avinashsai/Cross-domain-sentiment-analysis/master/Dataset/Actualdata/Books/Bookstest.txt\n",
        "  \n",
        "!wget https://raw.githubusercontent.com/avinashsai/Cross-domain-sentiment-analysis/master/Dataset/Actualdata/Dvd/Dvdtrain.txt\n",
        "!wget https://raw.githubusercontent.com/avinashsai/Cross-domain-sentiment-analysis/master/Dataset/Actualdata/Dvd/Dvdtest.txt\n",
        "  \n",
        "!wget https://raw.githubusercontent.com/avinashsai/Cross-domain-sentiment-analysis/master/Dataset/Actualdata/Electronics/Electronicstrain.txt\n",
        "!wget https://raw.githubusercontent.com/avinashsai/Cross-domain-sentiment-analysis/master/Dataset/Actualdata/Electronics/Electronicstest.txt\n",
        "  \n",
        "!wget https://raw.githubusercontent.com/avinashsai/Cross-domain-sentiment-analysis/master/Dataset/Actualdata/Kitchen/Kitchentrain.txt\n",
        "!wget https://raw.githubusercontent.com/avinashsai/Cross-domain-sentiment-analysis/master/Dataset/Actualdata/Kitchen/Kitchentest.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmByk8y5QpI_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import re\n",
        "import sys\n",
        "import pickle\n",
        "import time\n",
        "import copy\n",
        "from copy import deepcopy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split,StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import gensim\n",
        "from gensim.models import doc2vec,fasttext,FastText\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uw9v671ZQ_9X",
        "colab_type": "code",
        "outputId": "b0bfb991-fe8b-4ec8-fde9-027d4e281bcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.layers import *\n",
        "from keras.models import Model,Sequential\n",
        "from keras.callbacks import *\n",
        "from keras.metrics import *\n",
        "import keras.backend as K\n",
        "from keras.engine import Layer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2bt-b4JRV0_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(string):\n",
        "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
        "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
        "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
        "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
        "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
        "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
        "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
        "    string = re.sub(r\",\", \" , \", string)\n",
        "    string = re.sub(r\"!\", \" ! \", string)\n",
        "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
        "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
        "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
        "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
        "    return string.lower().strip()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XE2DwTRjRa1F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Xtrain = []\n",
        "with open('Dvdtrain.txt','r',encoding='latin1') as f:\n",
        "    for line in f.readlines():\n",
        "        Xtrain.append(preprocess(line[:-1]))\n",
        "\n",
        "ytrain = np.zeros(1600)\n",
        "ytrain[0:800] = 1\n",
        "Xtrain,ytrain = shuffle(Xtrain,ytrain,random_state=0)\n",
        "Xtrain,Xval,ytrain,yval = train_test_split(Xtrain,ytrain,test_size=0.2,random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgFR7p-wRc51",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Xtest = []\n",
        "with open('Dvdtest.txt','r',encoding='latin1') as f:\n",
        "    for line in f.readlines():\n",
        "        Xtest.append(preprocess(line[:-1]))\n",
        "\n",
        "ytest = np.zeros(400)\n",
        "ytest[0:200] = 1\n",
        "Xtest,ytest = shuffle(Xtest,ytest,random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YrShjg0RdAT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_l = len(Xtrain)\n",
        "val_l = len(Xval)\n",
        "test_l = len(Xtest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73F5iublRjhV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = []\n",
        "for sentence in Xtrain:\n",
        "    words.append(sentence.split())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZR7wY1CRlox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maxsenlen = 60\n",
        "batchsize = 32\n",
        "numepochs = 30"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzgxX99kQj3I",
        "colab_type": "text"
      },
      "source": [
        "## FastText + LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cyFCq_-pl00",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mincount = 1\n",
        "vecsize = 100\n",
        "winsize = 5\n",
        "totalepoch = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toTI6iV3B7f9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(0)\n",
        "ft = FastText(min_count=mincount,size=vecsize,window=winsize)\n",
        "ft.build_vocab(sentences=words)\n",
        "ft.train(sentences=words,total_examples=len(words),epochs=totalepoch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FzzS4J2RtEC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_vectors(sentence):\n",
        "    senlen = len(sentence.split())\n",
        "    maxlen = min(maxsenlen,senlen)\n",
        "    vec = [ft.wv[sentence[i]] for i  in range(maxlen) if sentence[i] in ft.wv.vocab]\n",
        "    if(len(vec)<maxsenlen):\n",
        "        vec+=[np.zeros(vecsize) for i in range(len(vec),maxsenlen)]\n",
        "    return np.asarray(vec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwIGXDIHRtHb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_vectors = np.zeros((train_l,maxsenlen,vecsize))\n",
        "for i in range(train_l):\n",
        "    train_vectors[i,:,:] = load_vectors(Xtrain[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NtMN159RtKP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_vectors = np.zeros((val_l,maxsenlen,vecsize))\n",
        "for i in range(val_l):\n",
        "    val_vectors[i,:,:] = load_vectors(Xval[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgkpNYs8RtOD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_vectors = np.zeros((test_l,maxsenlen,vecsize))\n",
        "for i in range(test_l):\n",
        "    test_vectors[i,:,:] = load_vectors(Xtest[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1UAJslhRtRA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_lstm():\n",
        "    inp = Input(shape=(maxsenlen,vecsize))\n",
        "    lstm1 = LSTM(100,recurrent_dropout=0.2,return_sequences=True)(inp)\n",
        "    lstm1 = LSTM(50,return_sequences=False)(lstm1)\n",
        "    out = Dense(1,activation='sigmoid')(lstm1)\n",
        "    \n",
        "    m1 = Model(inputs=inp,outputs=out)\n",
        "    return m1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xytBMbhMRtVO",
        "colab_type": "code",
        "outputId": "f7c7db09-a9d7-4ce0-b5bf-6c271964a293",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        }
      },
      "source": [
        "np.random.seed(0)\n",
        "runs = 5\n",
        "times= []\n",
        "avg_acc= 0.0\n",
        "avg_f1 = 0.0\n",
        "for run in range(runs):\n",
        "    model1 = model_lstm()\n",
        "    if(run==0):\n",
        "        print(model1.summary())\n",
        "    model1.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "    starttime = time.time()\n",
        "    stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='min')\n",
        "    check = ModelCheckpoint('temp.h5' ,monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=True, mode='min', period=1)\n",
        "    model1.fit(train_vectors,ytrain,validation_data=(val_vectors,yval),callbacks=[stop,check],batch_size=batchsize,\n",
        "              epochs=numepochs,verbose=0)\n",
        "    times.append(time.time()-starttime)\n",
        "    ypred = model1.predict(test_vectors,128)\n",
        "    ypred = (ypred>0.5)\n",
        "    avg_f1+=f1_score(ypred,ytest)\n",
        "    avg_acc+=accuracy_score(ypred,ytest)\n",
        "    \n",
        "print(\"F1 Score {} \".format(avg_f1/runs))\n",
        "print(\"Accuracy Score {} \".format(avg_acc/runs))\n",
        "print(\"Avg_time  {}\".format(np.mean(np.asarray(times))))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0717 18:22:30.005206 140103271364480 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0717 18:22:30.041442 140103271364480 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0717 18:22:30.048385 140103271364480 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0717 18:22:30.157660 140103271364480 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0717 18:22:30.167661 140103271364480 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0717 18:22:30.679429 140103271364480 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0717 18:22:30.700223 140103271364480 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0717 18:22:30.707405 140103271364480 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 60, 100)           0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 60, 100)           80400     \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 50)                30200     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 110,651\n",
            "Trainable params: 110,651\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "F1 Score 0.4544378186474084 \n",
            "Accuracy Score 0.48999999999999994 \n",
            "Avg_time  95.15033717155457\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVPJEPR5R7ob",
        "colab_type": "text"
      },
      "source": [
        "## PV(DBOW)+FNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxAwuGLrR3x8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tagged_documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(words)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlW53X-eR36R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(0)\n",
        "pv_dbow = Doc2Vec(vector_size=vecsize, window=2, min_count=1, workers=4)\n",
        "pv_dbow.build_vocab(tagged_documents)\n",
        "pv_dbow.train(tagged_documents,total_examples=pv_dbow.corpus_count,epochs=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfWjxEolR4Am",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_vectors = np.zeros((train_l,vecsize))\n",
        "for i in range(train_l):\n",
        "  train_vectors[i] = pv_dbow.infer_vector(Xtrain[i].split())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzjB5uzSAOXI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_vectors = np.zeros((val_l,vecsize))\n",
        "for i in range(val_l):\n",
        "  val_vectors[i] = pv_dbow.infer_vector(Xval[i].split())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUmwzT4rAWoQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_vectors = np.zeros((test_l,vecsize))\n",
        "for i in range(test_l):\n",
        "  test_vectors[i] = pv_dbow.infer_vector(Xtest[i].split())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Emn78yDNAeAs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_dense():\n",
        "    inp = Input(shape=(vecsize,))\n",
        "    dense1 = Dense(50,activation='relu')(inp)\n",
        "    dense1 = Dropout(0.5)(dense1)\n",
        "    dense1 = Dense(16,activation='relu')(dense1)\n",
        "    dense1 = Dropout(0.5)(dense1)\n",
        "    out = Dense(1,activation='sigmoid')(dense1)\n",
        "    m1 = Model(inputs=inp,outputs=out)\n",
        "    return m1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TV1_Vi9SAeHb",
        "colab_type": "code",
        "outputId": "e55e1fca-e7e6-4945-f6e4-a3cbaaf98a38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "np.random.seed(0)\n",
        "runs = 5\n",
        "times= []\n",
        "avg_acc= 0.0\n",
        "avg_f1 = 0.0\n",
        "for run in range(runs):\n",
        "    model2 = model_dense()\n",
        "    if(run==0):\n",
        "        print(model2.summary())\n",
        "    model2.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "    starttime = time.time()\n",
        "    stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='min')\n",
        "    check = ModelCheckpoint('temp.h5' ,monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=True, mode='min', period=1)\n",
        "    model2.fit(train_vectors,ytrain,validation_data=(val_vectors,yval),callbacks=[stop,check],batch_size=batchsize,\n",
        "              epochs=numepochs,verbose=0)\n",
        "    times.append(time.time()-starttime)\n",
        "    ypred = model2.predict(test_vectors,128)\n",
        "    ypred = (ypred>0.5)\n",
        "    avg_f1+=f1_score(ypred,ytest)\n",
        "    avg_acc+=accuracy_score(ypred,ytest)\n",
        "    \n",
        "print(\"F1 Score {} \".format(avg_f1/runs))\n",
        "print(\"Accuracy Score {} \".format(avg_acc/runs))\n",
        "print(\"Avg_time  {}\".format(np.mean(np.asarray(times))))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 16)                816       \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 5,883\n",
            "Trainable params: 5,883\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "F1 Score 0.713533463323069 \n",
            "Accuracy Score 0.6925 \n",
            "Avg_time  7.200384712219238\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMhjsI5VBJ5T",
        "colab_type": "text"
      },
      "source": [
        "### PV(DM)+FNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_Kq4cUDBMb-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(0)\n",
        "pv_dm = Doc2Vec(dm=1,vector_size=vecsize, window=2, min_count=1, workers=4)\n",
        "pv_dm.build_vocab(tagged_documents)\n",
        "pv_dm.train(tagged_documents,total_examples=pv_dm.corpus_count,epochs=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SBVyziVBTD-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_vectors = np.zeros((train_l,vecsize))\n",
        "for i in range(train_l):\n",
        "  train_vectors[i] = pv_dm.infer_vector(Xtrain[i].split())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvr8EpxKBUjM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_vectors = np.zeros((val_l,vecsize))\n",
        "for i in range(val_l):\n",
        "  val_vectors[i] = pv_dm.infer_vector(Xval[i].split())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q45psM-ZBUve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_vectors = np.zeros((test_l,vecsize))\n",
        "for i in range(test_l):\n",
        "  test_vectors[i] = pv_dm.infer_vector(Xtest[i].split())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vENSSbViBgjr",
        "colab_type": "code",
        "outputId": "a5f6a6f8-5a28-49c9-abc2-19737b66ceb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "np.random.seed(0)\n",
        "runs = 5\n",
        "times= []\n",
        "avg_acc= 0.0\n",
        "avg_f1 = 0.0\n",
        "for run in range(runs):\n",
        "    model2 = model_dense()\n",
        "    if(run==0):\n",
        "        print(model2.summary())\n",
        "    model2.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "    starttime = time.time()\n",
        "    stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='min')\n",
        "    check = ModelCheckpoint('temp.h5' ,monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=True, mode='min', period=1)\n",
        "    model2.fit(train_vectors,ytrain,validation_data=(val_vectors,yval),callbacks=[stop,check],batch_size=batchsize,\n",
        "              epochs=numepochs,verbose=0)\n",
        "    times.append(time.time()-starttime)\n",
        "    ypred = model2.predict(test_vectors,128)\n",
        "    ypred = (ypred>0.5)\n",
        "    avg_f1+=f1_score(ypred,ytest)\n",
        "    avg_acc+=accuracy_score(ypred,ytest)\n",
        "    \n",
        "print(\"F1 Score {} \".format(avg_f1/runs))\n",
        "print(\"Accuracy Score {} \".format(avg_acc/runs))\n",
        "print(\"Avg_time  {}\".format(np.mean(np.asarray(times))))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_11 (InputLayer)        (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 16)                816       \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 5,883\n",
            "Trainable params: 5,883\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "F1 Score 0.7054927054940985 \n",
            "Accuracy Score 0.6910000000000001 \n",
            "Avg_time  7.920228624343872\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUC7zU52B_tT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_index = {}\n",
        "with open('glove.840B.300d.txt','r',encoding='utf-8') as f:\n",
        "  for line in f.readlines():\n",
        "    ws = line.split(' ')\n",
        "    word = ws[0]\n",
        "    vector = np.asarray(ws[1:],'float32')\n",
        "    embedding_index[word] = vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQRzJI1rDRPd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maxsenlen = 60\n",
        "embeddim = 300"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLAaZV3rCfxe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tok = Tokenizer()\n",
        "tok.fit_on_texts(Xtrain)\n",
        "\n",
        "word_index = tok.word_index\n",
        "\n",
        "train = tok.texts_to_sequences(Xtrain)\n",
        "train_vectors = pad_sequences(train,maxsenlen)\n",
        "\n",
        "val = tok.texts_to_sequences(Xval)\n",
        "val_vectors = pad_sequences(val,maxsenlen)\n",
        "\n",
        "test = tok.texts_to_sequences(Xtest)\n",
        "test_vectors = pad_sequences(test,maxsenlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYC1acvCDJeu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_matrix = np.zeros((len(word_index)+1,embeddim))\n",
        "for word, i in word_index.items():\n",
        "  embedding_vector = embedding_index.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPh3izpYDDBB",
        "colab_type": "text"
      },
      "source": [
        "### LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOWfJXRlDEyl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lstm_model():\n",
        "  inp = Input(shape=(maxsenlen,))\n",
        "  \n",
        "  embed = Embedding(len(word_index)+1,embeddim,weights=[embedding_matrix],trainable=False)(inp)\n",
        "  \n",
        "  lstm_out = LSTM(100,recurrent_dropout=0.2,return_sequences=True)(embed)\n",
        "  lstm_out = LSTM(50,return_sequences=False)(lstm_out)\n",
        "  \n",
        "  out = Dense(16,activation='relu')(lstm_out)\n",
        "  out = Dropout(0.5)(out)\n",
        "  out = Dense(1,activation='sigmoid')(out)\n",
        "  \n",
        "  m2 = Model(inputs=inp,outputs=[out])\n",
        "  return m2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGvd2yayF8qP",
        "colab_type": "code",
        "outputId": "396d8264-f075-423e-c1e8-b830699d3a2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "np.random.seed(0)\n",
        "runs = 5\n",
        "times= []\n",
        "avg_acc= 0.0\n",
        "avg_f1 = 0.0\n",
        "for run in range(runs):\n",
        "    model3 = lstm_model()\n",
        "    if(run==0):\n",
        "        print(model3.summary())\n",
        "    model3.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "    starttime = time.time()\n",
        "    stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='min')\n",
        "    check = ModelCheckpoint('temp.h5' ,monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=True, mode='min', period=1)\n",
        "    model3.fit(train_vectors,ytrain,validation_data=(val_vectors,yval),callbacks=[stop,check],batch_size=batchsize,\n",
        "              epochs=numepochs,verbose=0)\n",
        "    times.append(time.time()-starttime)\n",
        "    ypred = model3.predict(test_vectors,128)\n",
        "    ypred = (ypred>0.5)\n",
        "    avg_f1+=f1_score(ypred,ytest)\n",
        "    avg_acc+=accuracy_score(ypred,ytest)\n",
        "    \n",
        "print(\"F1 Score {} \".format(avg_f1/runs))\n",
        "print(\"Accuracy Score {} \".format(avg_acc/runs))\n",
        "print(\"Avg_time  {}\".format(np.mean(np.asarray(times))))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_16 (InputLayer)        (None, 60)                0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 60, 300)           5311500   \n",
            "_________________________________________________________________\n",
            "lstm_11 (LSTM)               (None, 60, 100)           160400    \n",
            "_________________________________________________________________\n",
            "lstm_12 (LSTM)               (None, 50)                30200     \n",
            "_________________________________________________________________\n",
            "dense_36 (Dense)             (None, 16)                816       \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 5,502,933\n",
            "Trainable params: 191,433\n",
            "Non-trainable params: 5,311,500\n",
            "_________________________________________________________________\n",
            "None\n",
            "F1 Score 0.7365149759612175 \n",
            "Accuracy Score 0.7230000000000001 \n",
            "Avg_time  135.7540807723999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIEErLZDGNoF",
        "colab_type": "text"
      },
      "source": [
        "## Bi-LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2FQXj6WGPrL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bilstm_model():\n",
        "  inp = Input(shape=(maxsenlen,))\n",
        "  \n",
        "  embed = Embedding(len(word_index)+1,embeddim,weights=[embedding_matrix],trainable=False)(inp)\n",
        "  \n",
        "  lstm_out = Bidirectional(LSTM(100,recurrent_dropout=0.2,return_sequences=True))(embed)\n",
        "  lstm_out = Bidirectional(LSTM(50,return_sequences=False))(lstm_out)\n",
        "  \n",
        "  out = Dense(16,activation='relu')(lstm_out)\n",
        "  out = Dropout(0.5)(out)\n",
        "  out = Dense(1,activation='sigmoid')(out)\n",
        "  \n",
        "  m3 = Model(inputs=inp,outputs=[out])\n",
        "  return m3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63qwfrofGegi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "a27e93a3-fb66-411b-a00a-28ab999e553c"
      },
      "source": [
        "np.random.seed(0)\n",
        "runs = 5\n",
        "times= []\n",
        "avg_acc= 0.0\n",
        "avg_f1 = 0.0\n",
        "for run in range(runs):\n",
        "    model4 = bilstm_model()\n",
        "    if(run==0):\n",
        "        print(model4.summary())\n",
        "    model4.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "    starttime = time.time()\n",
        "    stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='min')\n",
        "    check = ModelCheckpoint('temp.h5' ,monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=True, mode='min', period=1)\n",
        "    model4.fit(train_vectors,ytrain,validation_data=(val_vectors,yval),callbacks=[stop,check],batch_size=batchsize,\n",
        "              epochs=numepochs,verbose=0)\n",
        "    times.append(time.time()-starttime)\n",
        "    ypred = model4.predict(test_vectors,128)\n",
        "    ypred = (ypred>0.5)\n",
        "    avg_f1+=f1_score(ypred,ytest)\n",
        "    avg_acc+=accuracy_score(ypred,ytest)\n",
        "    \n",
        "print(\"F1 Score {} \".format(avg_f1/runs))\n",
        "print(\"Accuracy Score {} \".format(avg_acc/runs))\n",
        "print(\"Avg_time  {}\".format(np.mean(np.asarray(times))))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_21 (InputLayer)        (None, 60)                0         \n",
            "_________________________________________________________________\n",
            "embedding_6 (Embedding)      (None, 60, 300)           5311500   \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 60, 200)           320800    \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 100)               100400    \n",
            "_________________________________________________________________\n",
            "dense_46 (Dense)             (None, 16)                1616      \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_47 (Dense)             (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 5,734,333\n",
            "Trainable params: 422,833\n",
            "Non-trainable params: 5,311,500\n",
            "_________________________________________________________________\n",
            "None\n",
            "F1 Score 0.7501267314430633 \n",
            "Accuracy Score 0.748 \n",
            "Avg_time  262.8179522037506\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWRxyyhtIqbg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_filters = 100\n",
        "filter_sizes = [3,4,5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdIm36SOSdv0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drop = 0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jL1YFm1TIKxt",
        "colab_type": "text"
      },
      "source": [
        "## Random CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otWPSEGBGrCz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def random_cnn():\n",
        "  inp = Input(shape=(maxsenlen,), dtype='int32')\n",
        "  embedding = Embedding(input_dim=len(word_index)+1, output_dim=embeddim, input_length=maxsenlen)(inp)\n",
        "  reshape = Reshape((maxsenlen,embeddim,1))(embedding)\n",
        "\n",
        "  conv_0 = Conv2D(num_filters, kernel_size=(filter_sizes[0], embeddim), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
        "  conv_1 = Conv2D(num_filters, kernel_size=(filter_sizes[1], embeddim), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
        "  conv_2 = Conv2D(num_filters, kernel_size=(filter_sizes[2], embeddim), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
        "\n",
        "  maxpool_0 = MaxPool2D(pool_size=(maxsenlen - filter_sizes[0] + 1, 1), strides=(1,1), padding='valid')(conv_0)\n",
        "  maxpool_1 = MaxPool2D(pool_size=(maxsenlen - filter_sizes[1] + 1, 1), strides=(1,1), padding='valid')(conv_1)\n",
        "  maxpool_2 = MaxPool2D(pool_size=(maxsenlen - filter_sizes[2] + 1, 1), strides=(1,1), padding='valid')(conv_2)\n",
        "\n",
        "  concatenated_tensor = Concatenate(axis=1)([maxpool_0, maxpool_1, maxpool_2])\n",
        "  flatten = Flatten()(concatenated_tensor)\n",
        "  dropout = Dropout(drop)(flatten)\n",
        "  output = Dense(units=1, activation='sigmoid')(dropout)\n",
        "  \n",
        "  m4 = Model(inputs=inp,outputs=output)\n",
        "  return m4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SBhJAaqJEOm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "outputId": "43abe957-70ae-4c82-eb4a-3102a2ccfd62"
      },
      "source": [
        "np.random.seed(0)\n",
        "runs = 5\n",
        "times= []\n",
        "avg_acc= 0.0\n",
        "avg_f1 = 0.0\n",
        "for run in range(runs):\n",
        "    model5 = random_cnn()\n",
        "    if(run==0):\n",
        "        print(model5.summary())\n",
        "    model5.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "    starttime = time.time()\n",
        "    stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='min')\n",
        "    check = ModelCheckpoint('temp.h5' ,monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=True, mode='min', period=1)\n",
        "    model5.fit(train_vectors,ytrain,validation_data=(val_vectors,yval),callbacks=[stop,check],batch_size=batchsize,\n",
        "              epochs=numepochs,verbose=0)\n",
        "    times.append(time.time()-starttime)\n",
        "    ypred = model5.predict(test_vectors,128)\n",
        "    ypred = (ypred>0.5)\n",
        "    avg_f1+=f1_score(ypred,ytest)\n",
        "    avg_acc+=accuracy_score(ypred,ytest)\n",
        "    \n",
        "print(\"F1 Score {} \".format(avg_f1/runs))\n",
        "print(\"Accuracy Score {} \".format(avg_acc/runs))\n",
        "print(\"Avg_time  {}\".format(np.mean(np.asarray(times))))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0717 19:15:05.003151 140103271364480 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_27 (InputLayer)           (None, 60)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_12 (Embedding)        (None, 60, 300)      5311500     input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 60, 300, 1)   0           embedding_12[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 58, 1, 100)   90100       reshape_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 57, 1, 100)   120100      reshape_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 56, 1, 100)   150100      reshape_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 1, 1, 100)    0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 1, 1, 100)    0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 1, 1, 100)    0           conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 1, 100)    0           max_pooling2d_1[0][0]            \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 300)          0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_31 (Dropout)            (None, 300)          0           flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_56 (Dense)                (None, 1)            301         dropout_31[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 5,672,101\n",
            "Trainable params: 5,672,101\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "F1 Score 0.710172312245321 \n",
            "Accuracy Score 0.712 \n",
            "Avg_time  22.45720467567444\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1D2zVmyJNh2",
        "colab_type": "text"
      },
      "source": [
        "### Static CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kko75slJJOon",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def static_cnn():\n",
        "  inp = Input(shape=(maxsenlen,), dtype='int32')\n",
        "  embedding = Embedding(input_dim=len(word_index)+1, output_dim=embeddim, weights=[embedding_matrix],trainable=False)(inp)\n",
        "  reshape = Reshape((maxsenlen,embeddim,1))(embedding)\n",
        "\n",
        "  conv_0 = Conv2D(num_filters, kernel_size=(filter_sizes[0], embeddim), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
        "  conv_1 = Conv2D(num_filters, kernel_size=(filter_sizes[1], embeddim), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
        "  conv_2 = Conv2D(num_filters, kernel_size=(filter_sizes[2], embeddim), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
        "\n",
        "  maxpool_0 = MaxPool2D(pool_size=(maxsenlen - filter_sizes[0] + 1, 1), strides=(1,1), padding='valid')(conv_0)\n",
        "  maxpool_1 = MaxPool2D(pool_size=(maxsenlen - filter_sizes[1] + 1, 1), strides=(1,1), padding='valid')(conv_1)\n",
        "  maxpool_2 = MaxPool2D(pool_size=(maxsenlen - filter_sizes[2] + 1, 1), strides=(1,1), padding='valid')(conv_2)\n",
        "\n",
        "  concatenated_tensor = Concatenate(axis=1)([maxpool_0, maxpool_1, maxpool_2])\n",
        "  flatten = Flatten()(concatenated_tensor)\n",
        "  dropout = Dropout(drop)(flatten)\n",
        "  output = Dense(units=1, activation='sigmoid')(dropout)\n",
        "  \n",
        "  m5 = Model(inputs=inp,outputs=output)\n",
        "  return m5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRzXyau5JYzq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "a883966b-612a-4aff-9937-5d9cd50fab64"
      },
      "source": [
        "np.random.seed(0)\n",
        "runs = 5\n",
        "times= []\n",
        "avg_acc= 0.0\n",
        "avg_f1 = 0.0\n",
        "for run in range(runs):\n",
        "    model6 = random_cnn()\n",
        "    if(run==0):\n",
        "        print(model6.summary())\n",
        "    model6.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "    starttime = time.time()\n",
        "    stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='min')\n",
        "    check = ModelCheckpoint('temp.h5' ,monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=True, mode='min', period=1)\n",
        "    model6.fit(train_vectors,ytrain,validation_data=(val_vectors,yval),callbacks=[stop,check],batch_size=batchsize,\n",
        "              epochs=numepochs,verbose=0)\n",
        "    times.append(time.time()-starttime)\n",
        "    ypred = model6.predict(test_vectors,128)\n",
        "    ypred = (ypred>0.5)\n",
        "    avg_f1+=f1_score(ypred,ytest)\n",
        "    avg_acc+=accuracy_score(ypred,ytest)\n",
        "    \n",
        "print(\"F1 Score {} \".format(avg_f1/runs))\n",
        "print(\"Accuracy Score {} \".format(avg_acc/runs))\n",
        "print(\"Avg_time  {}\".format(np.mean(np.asarray(times))))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_32 (InputLayer)           (None, 60)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_17 (Embedding)        (None, 60, 300)      5311500     input_32[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "reshape_6 (Reshape)             (None, 60, 300, 1)   0           embedding_17[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 58, 1, 100)   90100       reshape_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 57, 1, 100)   120100      reshape_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 56, 1, 100)   150100      reshape_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling2D) (None, 1, 1, 100)    0           conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling2D) (None, 1, 1, 100)    0           conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_18 (MaxPooling2D) (None, 1, 1, 100)    0           conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 3, 1, 100)    0           max_pooling2d_16[0][0]           \n",
            "                                                                 max_pooling2d_17[0][0]           \n",
            "                                                                 max_pooling2d_18[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "flatten_6 (Flatten)             (None, 300)          0           concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_36 (Dropout)            (None, 300)          0           flatten_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_61 (Dense)                (None, 1)            301         dropout_36[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 5,672,101\n",
            "Trainable params: 5,672,101\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "F1 Score 0.7078544565242116 \n",
            "Accuracy Score 0.7100000000000001 \n",
            "Avg_time  22.711619567871093\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pcbd97H1U6He",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}